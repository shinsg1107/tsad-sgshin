from yacs.config import CfgNode as CN


_C = CN()
# random seed number
_C.SEED = 0
# number of gpus per node
_C.NUM_GPUS = 4
_C.VISIBLE_DEVICES = 0
_C.RESULT_DIR = 'results/'



_C.DATA_LOADER = CN()
# the number of data loading workers per gpu
_C.DATA_LOADER.NUM_WORKERS = 4
_C.DATA_LOADER.PIN_MEMORY = True
_C.DATA_LOADER.DROP_LAST = True



_C.DATA = CN()
_C.DATA.BASE_DIR = 'data/'
_C.DATA.NAME = 'SWaT'
_C.DATA.SCALE = "standard"
_C.DATA.WIN_SIZE = 10
_C.DATA.TRAIN_STEP = 1
_C.DATA.TEST_STEP = 1
_C.DATA.N_VAR = 51
_C.DATA.TRAIN_RATIO = 0.8
_C.DATA.DOWNSAMPLE_RATE = 1



_C.TRAIN = CN()
_C.TRAIN.ENABLE = True
_C.TRAIN.BATCH_SIZE = 1024
_C.TRAIN.SHUFFLE = True
_C.TRAIN.DROP_LAST = True
_C.TRAIN.SPLIT = 'train'
# directory to save checkpoints
_C.TRAIN.CHECKPOINT_DIR = 'results/'
# path to checkpoint to resume training
_C.TRAIN.RESUME = ''
# epoch period to evaluate on a validation set
_C.TRAIN.EVAL_PERIOD = 5
# iteration frequency to print progress meter
_C.TRAIN.PRINT_FREQ = 100
_C.TRAIN.METRIC_BEST = float("inf")
_C.TRAIN.IS_METRIC_LOWER_BETTER = True



_C.VAL = CN()
_C.VAL.SPLIT = 'val'
_C.VAL.BATCH_SIZE = 1024
_C.VAL.SHUFFLE = False
_C.VAL.DROP_LAST = False
_C.VAL.VIS = False



_C.TEST = CN()
_C.TEST.ENABLE = True
_C.TEST.SPLIT = 'test'
_C.TEST.BATCH_SIZE = 1024
_C.TEST.SHUFFLE = False
_C.TEST.DROP_LAST = False
_C.TEST.POINT_ADJUST = True
_C.TEST.VIS = True
_C.TEST.THRESHOLD = CN()
_C.TEST.THRESHOLD.TYPE = 'best_f1'  # ratio, best_f1
_C.TEST.THRESHOLD.ANOMALY_RATIO = 0.5
_C.TEST.ANOMALY_SCORES_DIR = ""



_C.SOLVER = CN()
_C.SOLVER.START_EPOCH = 0
_C.SOLVER.MAX_EPOCH = 30
_C.SOLVER.OPTIMIZING_METHOD = 'adam'
_C.SOLVER.BASE_LR = 0.0001
_C.SOLVER.WEIGHT_DECAY = 0.0001
_C.SOLVER.MOMENTUM = 0.9
_C.SOLVER.NESTEROV = True
_C.SOLVER.DAMPENING = 0.0
_C.SOLVER.LR_POLICY = 'cosine'
_C.SOLVER.COSINE_END_LR = 0.0
_C.SOLVER.COSINE_AFTER_WARMUP = True
_C.SOLVER.WARMUP_EPOCHS = 5
_C.SOLVER.WARMUP_START_LR = 0.0001
_C.SOLVER.GRADIENT_CLIP = True
_C.SOLVER.GRADIENT_CLIP_NORM = 0.5



_C.MODEL = CN()
_C.MODEL.NAME = 'ORACLEAD'

_C.ORACLEAD = CN()

#ORACLEAD
_C.ORACLEAD.METRIC_NAMES = ("Total", "Pred", "Recon", "Dev")
_C.ORACLEAD.LOSS_NAMES   = ("Total", "Pred", "Recon", "Dev")

_C.ORACLEAD.LAMBDA_RECON = 0.1
_C.ORACLEAD.LAMBDA_DEV   = 3

_C.ORACLEAD.SLS = CN()
_C.ORACLEAD.SLS.START_EPOCH = 1   
_C.ORACLEAD.SLS.SAVE_EVERY_EPOCH = True

#LSTM Encoder
_C.ORACLEAD.LSTM_ENCODER = CN()
_C.ORACLEAD.LSTM_ENCODER.INPUT_DIM = 1
_C.ORACLEAD.LSTM_ENCODER.HIDDEN_DIM = 128
_C.ORACLEAD.LSTM_ENCODER.NUM_LAYERS = 2
_C.ORACLEAD.LSTM_ENCODER.DROPOUT = 0.1
_C.ORACLEAD.LSTM_ENCODER.BIDIRECTIONAL = False
_C.ORACLEAD.LSTM_ENCODER.SHARED = False

#MHSA
_C.ORACLEAD.MHSA = CN()
_C.ORACLEAD.MHSA.BACKEND = "torch"   # paper or torch (paper는 논문 수식 그대로 구현)
_C.ORACLEAD.MHSA.DIM = 128           # = causal embedding dim (LSTM out_dim과 일치)
_C.ORACLEAD.MHSA.NUM_HEADS = 4
_C.ORACLEAD.MHSA.BIAS = True

_C.ORACLEAD.MHSA.ATTN_DROPOUT = 0.1
_C.ORACLEAD.MHSA.PROJ_DROPOUT = 0.1  # 없으면 DROPOUT을 fallback
_C.ORACLEAD.MHSA.DROPOUT = 0.1       # optional fallback

_C.ORACLEAD.MHSA.PRE_NORM = True
_C.ORACLEAD.MHSA.RESIDUAL = True
_C.ORACLEAD.MHSA.MASK_SELF = False   # optional

#LSTM Decoder
_C.ORACLEAD.DECODER = CN()
_C.ORACLEAD.DECODER.DIM = 128          
_C.ORACLEAD.DECODER.HIDDEN_DIM = 128
_C.ORACLEAD.DECODER.NUM_LAYERS = 2
_C.ORACLEAD.DECODER.DROPOUT = 0.0
_C.ORACLEAD.DECODER.BIAS = True
_C.ORACLEAD.DECODER.BIDIRECTIONAL = False

_C.ORACLEAD.DECODER.OUT_DIM = 1        # sensor value dimension
_C.ORACLEAD.DECODER.PAST_LEN = 9       # L-1 (예: WIN_SIZE=10이면 9)
_C.ORACLEAD.DECODER.SHARED = False     # 논문처럼 변수별 decoder면 False


_C.SCORER = CN()
_C.SCORER.TYPE = 'l2'  # l2, cos

def get_cfg_defaults():

    return _C.clone()
